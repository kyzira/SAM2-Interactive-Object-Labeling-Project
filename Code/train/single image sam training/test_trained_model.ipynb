{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ef6d9c-0c31-4afb-9639-cbb1483dd981",
   "metadata": {},
   "source": [
    "# Test trained Model\n",
    "You can run this notebook to see, how the training affects the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b96d471-2e9c-480d-8533-cbb0dde0ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment image region using  fine tune model\n",
    "# See Train.py on how to fine tune/train the model\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b3cb8677-85ef-44a0-bb06-58c9832a6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bfloat16 for the entire script (memory efficient)\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad632c1b",
   "metadata": {},
   "source": [
    "Select the Image to be segmented. Also add the mask, from this mask num_samples amount of points will be randomly chosen to be added to sam2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0248319-428b-4bea-b1ac-7f4325b92a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"C:\\Users\\K3000\\Desktop\\conversion test\\new format\\Images\\3M0030_3M0030_3M0033_D_11122017_141731.mpg_01475.jpg\" # path to image\n",
    "mask_path = r\"C:\\Users\\K3000\\Desktop\\conversion test\\new format\\Masks\\3M0030_3M0030_3M0033_D_11122017_141731.mpg_01475.png\" # path to mask, the mask will define the image region to segment\n",
    "num_samples = 10 # number of points/segment to sample\n",
    "\n",
    "# Switch this to false if you want to see the untrained model results\n",
    "use_trained_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5b193c2d-5957-4fba-9f7d-a46fd3d5e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, mask_path): # read and resize image and mask\n",
    "        img = cv2.imread(image_path)[...,::-1]  # read image\n",
    "        mask = cv2.imread(mask_path,0)\n",
    "        r = np.min([1024 / img.shape[1], 1024 / img.shape[0]])\n",
    "        img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))\n",
    "        mask = cv2.resize(mask, (int(mask.shape[1] * r), int(mask.shape[0] * r)),interpolation=cv2.INTER_NEAREST)\n",
    "        return img, mask\n",
    "def get_points(mask,num_points): # Sample points inside the input mask\n",
    "        points=[]\n",
    "        for i in range(num_points):\n",
    "            coords = np.argwhere(mask > 0)\n",
    "            yx = np.array(coords[np.random.randint(len(coords))])\n",
    "            points.append([[yx[1], yx[0]]])\n",
    "        return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72c25486-9eb3-4cf7-8595-2269e344c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image and sample points\n",
    "image,mask = read_image(image_path, mask_path)\n",
    "input_points = get_points(mask,num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a7abf3c-cd72-475e-ae4c-9a63d29d4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model you need to have pretrained model already made\n",
    "sam2_checkpoint = r\"C:\\Users\\K3000\\sam2\\checkpoints\\sam2.1_hiera_tiny.pt\" # path to model weight\n",
    "model_cfg = r\"C:\\Users\\K3000\\sam2\\sam2\\configs\\sam2.1\\sam2.1_hiera_t.yaml\" # model config\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "\n",
    "# Build net \n",
    "predictor = SAM2ImagePredictor(sam2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b3e52",
   "metadata": {},
   "source": [
    "Here you load your trained model, skip this step to see how sam performs without the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e6b2c8a-8fa8-4244-b56b-ad736233cc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_trained_model:\n",
    "    predictor.model.load_state_dict(torch.load(\"model.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "925e60d5-af14-4790-bb0b-97f88a8bb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict mask\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictor.set_image(image)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=input_points,\n",
    "        point_labels=np.ones([input_points.shape[0],1])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0835a5aa-a511-47ba-9158-e6b319401bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short predicted masks from high to low score\n",
    "\n",
    "np_masks = np.array(masks[:,0])\n",
    "np_scores = scores[:,0]\n",
    "shorted_masks = np_masks[np.argsort(np_scores)][::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ee2bdd4e-a5b1-4b05-81da-3a6346ed6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_masks = np.array(masks[:,0].numpy()) if isinstance(masks, torch.Tensor) else np.array(masks[:,0])\n",
    "np_scores = scores[:,0].float().numpy() if isinstance(scores, torch.Tensor) else np.array(scores[:,0])\n",
    "shorted_masks = np_masks[np.argsort(np_scores)][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb1b874e-50f6-48f2-bfcd-c7009861ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map = np.zeros_like(shorted_masks[0], dtype=np.uint8)\n",
    "occupancy_mask = np.zeros_like(shorted_masks[0], dtype=bool)\n",
    "\n",
    "for i in range(shorted_masks.shape[0]):\n",
    "    mask = shorted_masks[i]\n",
    "    if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n",
    "        continue\n",
    "    \n",
    "    # Convert mask to boolean when needed\n",
    "    mask_bool = mask.astype(bool)\n",
    "    \n",
    "    mask_bool[occupancy_mask] = False  # Set overlapping areas to False in the mask\n",
    "    seg_map[mask_bool] = i + 1         # Use boolean mask to index seg_map\n",
    "    occupancy_mask[mask_bool] = True   # Update occupancy_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b8c84d1-44ff-4bd8-a91e-f580ec263022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create colored annotation map\n",
    "height, width = seg_map.shape\n",
    "\n",
    "# Create an empty RGB image for the colored annotation\n",
    "rgb_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# Map each class number to a random  color\n",
    "\n",
    "\n",
    "for id_class in range(1,seg_map.max()+1):\n",
    "    rgb_image[seg_map == id_class] = [np.random.randint(255), np.random.randint(255), np.random.randint(255)]\n",
    "\n",
    "# save and display\n",
    "\n",
    "cv2.imwrite(\"annotation.png\",rgb_image)\n",
    "cv2.imwrite(\"mix.png\",(rgb_image/2+image/2).astype(np.uint8))\n",
    "\n",
    "cv2.imshow(\"annotation\",rgb_image)\n",
    "cv2.imshow(\"mix\",(rgb_image/2+image/2).astype(np.uint8))\n",
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79404bc3-ec15-46ea-bf3e-c5f6a82cbf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
